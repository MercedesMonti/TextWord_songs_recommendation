{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75232424-a1c0-4a39-fe3b-4efad3707541",
    "colab_type": "text",
    "id": "918NcvM_sM8U"
   },
   "source": [
    "The aim of this notebook is to make use of the word2vec model to find similar songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5639af0e-aa64-74bd-de5c-b6f5c50b041f",
    "colab": {},
    "colab_type": "code",
    "id": "flidHJ8TsM8V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.models.word2vec as w2v\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import pprint\n",
    "import sklearn.manifold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smart_open.gcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15369545-997e-e9f9-b1ac-02dff0031be3",
    "colab_type": "text",
    "id": "nRjV5XcFsM8Y"
   },
   "source": [
    "Though non english artists were removed, the dataset contained Hindi lyrics of Lata Mangeshkar written in English. Therefore, I decided to remove all songs sung by her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "61f9b0e5-e203-22c7-4cab-457133f7b80a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "EzAI44wPsM8Z",
    "outputId": "491e9197-b12a-4e5f-a538-a0e89ea191ea"
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"hhgroups_merge_28_05.csv\", header=0, encoding='utf-8')\n",
    "#songs.head()\n",
    "songs = songs[songs.artista != 'Lata Mangeshkar']\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f436501-4d68-c1d7-f418-5b13462780ef",
    "colab_type": "text",
    "id": "y_PeY9S2sM8b"
   },
   "source": [
    "To train the word2vec model, we first need to build its vocabulary. To do that, I iterated over each song and added it to an array that can later be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a6a957b3-8bec-4d26-6cc4-6a19d3d24f7d",
    "colab": {},
    "colab_type": "code",
    "id": "UoGo_kUmsM8c",
    "outputId": "9c50f32b-1cff-4c53-c72d-a99b0329a7e0"
   },
   "outputs": [],
   "source": [
    "text_corpus = []\n",
    "for song in songs['letra']:\n",
    "    words = song.lower().split()\n",
    "    text_corpus.append(words)\n",
    "\n",
    "\n",
    "# Dimensionality of the resulting word vectors.\n",
    "#more dimensions, more computationally expensive to train\n",
    "#but also more accurate\n",
    "#more dimensions = more generalized\n",
    "num_features = 50\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 1\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "#more workers, faster we train\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "\n",
    "downsampling = 1e-1\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "#random number generator\n",
    "#deterministic, good for debugging\n",
    "seed = 1\n",
    "\n",
    "songs2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")\n",
    "\n",
    "songs2vec.build_vocab(text_corpus)\n",
    "print (len(text_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "18363422-5ac9-77aa-1f58-cd745000ac6c",
    "colab_type": "text",
    "id": "bIFNfY0BsM8e",
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydJQHDOmfD-L"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "songs2vec.train(text_corpus, total_examples=songs2vec.corpus_count, epochs=2)\n",
    "\n",
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "\n",
    "songs2vec.save(os.path.join(\"trained\", \"songs2vectors.w2v\"))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0690a4a-10f5-d2ce-9dee-480a8b77d114",
    "colab": {},
    "colab_type": "code",
    "id": "lJBbRHyMsM8f"
   },
   "outputs": [],
   "source": [
    "songs2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"songs2vectors.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYVCqMIdsM8h"
   },
   "source": [
    "#### Let's explore our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6zeibuesM8h"
   },
   "source": [
    "Find similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Syo_JMRdsM8h",
    "outputId": "a0f55484-532d-4d82-b608-1aabaef5b66e"
   },
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"viajar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWYF4B6LsM8k",
    "outputId": "8d8e3883-5a3c-47dc-fe44-5191c235801e"
   },
   "outputs": [],
   "source": [
    "songs2vec.wv.most_similar(\"vacaciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRMNr3qDsM8m"
   },
   "source": [
    "Words out of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLbf-TTXsM8n",
    "outputId": "512968d0-1ccc-45e9-8837-0f29422852df"
   },
   "outputs": [],
   "source": [
    "songs2vec.wv.doesnt_match(\"te quiero\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1636A6VLsM8p",
    "outputId": "cdb11a99-2777-4646-fed8-2b33907b30f9"
   },
   "outputs": [],
   "source": [
    "songs2vec.most_similar(positive=['mujer', 'rey'], negative=['hombre'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1K-wzTtDsM8w"
   },
   "source": [
    "Semantic distance between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muvD22cJsM8x"
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = songs2vec.wv.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{0} es a {1}, lo que {2} es a {3}\".format(start1, end1, start2, end2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Tjyq8a7sM82",
    "outputId": "618a0981-6f6a-485b-b71d-948ebc7038d9"
   },
   "outputs": [],
   "source": [
    "nearest_similarity_cosmul(\"espa√±a\", \"mar\", \"tristeza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9f0fe3f-cbf8-e751-9d9a-acbaec2f0aad",
    "colab_type": "text",
    "id": "4BZHfgPDsM84"
   },
   "source": [
    "With the word vector embeddings in place, it is now time to calculate the normalised vector sum of each song. This process can take some time since it has to be done for each of 57,000 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d11b30f-e526-dd24-9084-d5f7dfd00058",
    "colab": {},
    "colab_type": "code",
    "id": "izE5GZDHsM85",
    "outputId": "796baf23-2b59-49a4-a94d-4a2667493fbf"
   },
   "outputs": [],
   "source": [
    "print(songs2vec['noche'])\n",
    "def songVector(row):\n",
    "    vector_sum = 0\n",
    "    words = row.lower().split()\n",
    "    for word in words:\n",
    "        vector_sum = vector_sum + songs2vec[word]\n",
    "    vector_sum = vector_sum.reshape(1,-1)\n",
    "    normalised_vector_sum = sklearn.preprocessing.normalize(vector_sum)\n",
    "    return normalised_vector_sum\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "songs['song_vector'] = songs['letra'].apply(songVector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "303a0106-9112-d06e-393c-8affc71a1e41",
    "colab_type": "text",
    "id": "ZtYEWjpRsM9F"
   },
   "source": [
    "**t-sne and random song selection** \n",
    "\n",
    "The songs have 50 dimensions each. Application of t-sne is memory intensive and hence it is slightly easier on the computer to use a random sample of the 57,000 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "028d8c5b-a7df-30a0-a1dc-fbb1442c77f4",
    "colab": {},
    "colab_type": "code",
    "id": "TfKKt8DGsM9G",
    "outputId": "15d2402d-77f6-4a10-ce06-2a6cb19c21dd"
   },
   "outputs": [],
   "source": [
    "song_vectors = []\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(songs, test_size = 0.9)\n",
    "\n",
    "\n",
    "for song_vector in train['song_vector']:\n",
    "    song_vectors.append(song_vector)\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af7db425-5b23-e106-738c-86039164ed82",
    "colab_type": "text",
    "id": "2BNp0JFZsM9I"
   },
   "source": [
    "I had a fairly measly 4gb machine and wasn't able to generate a more accurate model. However, one can play around with the number of iterations, learning rate and other factors to fit the model better. If you have too many dimensions (~300+), it might make sense to use PCA first and then t-sne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "031560ae-0460-2fed-6ef3-6fc5840db6ad",
    "colab": {},
    "colab_type": "code",
    "id": "JCcsVpBFsM9I",
    "outputId": "da8df1a1-61ed-473e-daef-8ea3236819d0"
   },
   "outputs": [],
   "source": [
    "X = np.array(song_vectors).reshape((932, 50))\n",
    "\n",
    "start_time = time.time()\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, n_iter=250, random_state=0, verbose=2)\n",
    "\n",
    "all_word_vectors_matrix_2d = tsne.fit_transform(X)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "245d45c2-4d47-7b36-83c1-065a04d6112e",
    "colab": {},
    "colab_type": "code",
    "id": "rSF8dlsvsM9K"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(all_word_vectors_matrix_2d,columns=['X','Y'])\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "train.head()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06e23870-3718-ac53-cf69-19efcc7983b0",
    "colab_type": "text",
    "id": "xQekBxIFsM9M"
   },
   "source": [
    "Joining two dataframes to obtain each song's corresponding X,Y co-ordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "774acb91-c804-4593-e5b3-a0cfc1de274c",
    "colab": {},
    "colab_type": "code",
    "id": "vo0e-muWsM9M",
    "outputId": "03a2dd7f-64c1-4d45-d2e5-3e33888ec3d3"
   },
   "outputs": [],
   "source": [
    "two_dimensional_songs = pd.concat([train, df], axis=1)\n",
    "\n",
    "two_dimensional_songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3be297f-924a-0026-de2a-532330697763",
    "colab_type": "text",
    "id": "JlFl-jaxsM9P"
   },
   "source": [
    "**Plotting the results**\n",
    "\n",
    "Using plotly, I plotted the results so that it becomes easier to explore similar songs based on their colors and clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d94bd43-4efb-8c1c-1646-561134c2eccd",
    "colab": {},
    "colab_type": "code",
    "id": "jppfM8odsM9P",
    "outputId": "f300a07b-cbb4-4e5c-a2ab-083d56fb09aa"
   },
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    y = two_dimensional_songs['Y'],\n",
    "    x = two_dimensional_songs['X'],\n",
    "    text = two_dimensional_songs['artista'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size= 5,#'7',\n",
    "        color = np.random.randn(5717), #set color equal to a variable\n",
    "        colorscale='Viridis',\n",
    "        showscale=True\n",
    "    )\n",
    ")\n",
    "data = [trace1]\n",
    "\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aB3f2IWSsM9S",
    "outputId": "7387948e-e65c-4695-de3a-2e0fcf08271b"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    y = two_dimensional_songs['Y'],\n",
    "    x = two_dimensional_songs['X'],\n",
    "    text = two_dimensional_songs['artista']+ \"_\"+two_dimensional_songs['cancion'] ,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size= 10,#'7',\n",
    "        color = np.random.randn(5717), #set color equal to a variable\n",
    "        colorscale='Viridis',\n",
    "        showscale=True\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DROhPgb8sM9U"
   },
   "outputs": [],
   "source": [
    "## LOOK FOR COMMON SONGS AND ANALYZE THE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8d6fd7b-5044-30d1-283a-517a462888c3",
    "colab": {},
    "colab_type": "code",
    "id": "ea6XRvGmsM9V",
    "outputId": "ce928c92-a523-4a1d-d1f2-65b79b618adf"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    y = np.random.randn(500),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=16,\n",
    "        color=np.random.randn(500), #set color equal to a variable\n",
    "        colorscale='Viridis', # one of plotly colorscales\n",
    "        showscale=True\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1og9i7LsM9X",
    "outputId": "b9c2beea-bd61-4edd-e603-c3a288b015a1"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_width',\n",
    "              color='species')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBBMTaxysM9Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 1,
  "_is_fork": false,
  "colab": {
   "name": "Copia de 4b_TEXT_word2vec-songs-recommendation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
